{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uinf: 31.677, alpha: -0.012950343049797924\n",
      "Datasets Loaded.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, pandas as pd\n",
    "import torch, os, logging\n",
    "\n",
    "from datetime import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from scipy.interpolate import griddata\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "from preprocessing import load_dataset, normalize, compute_minimum_distances\n",
    "\n",
    "# Set up Python logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "# Create a log directory with a timestamp to keep different runs separate\n",
    "logdir = os.path.join(\"logs\", datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "os.makedirs(logdir, exist_ok=True)\n",
    "writer = SummaryWriter(logdir)\n",
    "\n",
    "pd.set_option('display.precision', 20)\n",
    "\n",
    "# torch.manual_seed(1234)\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "#torch.set_printoptions(edgeitems=1000)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Load Data (change path if needed)\n",
    "    path = [\"airFoil2D_SST_31.283_-4.156_0.919_6.98_14.32\"]\n",
    "    train_data, len_list = load_dataset(path, \n",
    "                                       n_random_sampling = 0\n",
    "                                       )\n",
    "\n",
    "    Uinf, alpha, gamma_1, gamma_2, gamma_3 = float(path[0].split('_')[2]), float(path[0].split('_')[3])*np.pi/180, float(path[0].split('_')[4]), float(path[0].split('_')[5]), float(path[0].split('_')[6])\n",
    "    print(f\"Uinf: {Uinf}, alpha: {alpha}\")\n",
    "    \n",
    "    u_inlet, v_inlet = np.cos(alpha)*Uinf, np.sin(alpha)*Uinf\n",
    "    \n",
    "    df_train_input = pd.DataFrame(train_data[0].x_train, columns=[\"x\", \"y\", \"sdf\", \"x_n\", \"y_n\"])\n",
    "    df_train_target = pd.DataFrame(train_data[0].y_train, columns=[\"u\", \"v\", \"p\", \"nut\"])\n",
    "    df_train = pd.concat([df_train_input, df_train_target], axis=1) \n",
    "\n",
    "    df_train['u_inlet'] = u_inlet\n",
    "    df_train['v_inlet'] = v_inlet\n",
    "    df_train['gamma_1'] = gamma_1\n",
    "    df_train['gamma_2'] = gamma_2\n",
    "    df_train['gamma_3'] = gamma_3\n",
    "\n",
    "    df_box = df_train.iloc[len_list[0]:len_list[0]+len_list[1]+len_list[2],:]\n",
    "\n",
    "\n",
    "    # df = df_box[(df_box['x'] <= 4) & (df_box['x'] >= 1.5)]\n",
    "\n",
    "    # Define the grid limits\n",
    "    x_min, x_max = -2, 4\n",
    "    y_min, y_max = -1.5, 1.5\n",
    "\n",
    "    # Define the resolution of the grid\n",
    "    grid_resolution_x = 2000  # Number of points along x\n",
    "    grid_resolution_y = 1000  # Number of points along y\n",
    "\n",
    "    # Create grid points\n",
    "    grid_x = np.linspace(x_min, x_max, grid_resolution_x)\n",
    "    grid_y = np.linspace(y_min, y_max, grid_resolution_y)\n",
    "    grid = np.meshgrid(grid_x, grid_y)\n",
    "\n",
    "    # Create grid points\n",
    "    grid_points = np.vstack([grid[0].ravel(), grid[1].ravel()]).T\n",
    "\n",
    "    # For demonstration, interpolating 'x_n' feature\n",
    "    features = df_box[['x', 'y', \"sdf\", \"x_n\", \"y_n\", 'u_inlet', 'v_inlet', 'gamma_1', 'gamma_2', 'gamma_3']].to_numpy()\n",
    "    outputs = df_box[['x', 'y', 'u', 'v', 'p', 'nut']].to_numpy()\n",
    "\n",
    "    # Perform interpolation\n",
    "    features_grid = griddata(features[:, :2], features, grid_points, method='linear')\n",
    "    outputs_grid = griddata(features[:, :2], outputs, grid_points, method='linear')\n",
    "\n",
    "    # Reshape the results to the grid shape\n",
    "    interpolated_feature = features_grid.reshape((10, grid_resolution_x, grid_resolution_y))\n",
    "    output_interpolated_reshaped = outputs_grid.reshape((6, grid_resolution_x, grid_resolution_y))\n",
    "\n",
    "    x_y_tensor = torch.from_numpy(interpolated_feature[:2]).float().requires_grad_(True)\n",
    "    other_features_tensor = torch.from_numpy(interpolated_feature[2:]).float()\n",
    "\n",
    "    input_tensor_torch = torch.cat([x_y_tensor, other_features_tensor], dim=0).unsqueeze(0)\n",
    "    output_tensor_torch = torch.from_numpy(output_interpolated_reshaped[np.newaxis, ...])\n",
    "\n",
    "    print(\"Datasets Loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FourierNeuralOperatorNN import FourierNeuralOperatorNN\n",
    "from plot import plot_predictions_vs_test, plot_test\n",
    "\n",
    "# Train the model\n",
    "model = FourierNeuralOperatorNN(input_tensor_torch, output_tensor_torch)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Let's use {torch.cuda.device_count()} GPUs!\")\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    \n",
    "# Check for CUDA availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "print(f\"Started Training.\")\n",
    "model.train(1)\n",
    "print(f\"Finished Training.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
